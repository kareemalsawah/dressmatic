{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Outfit_model.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "hbZKTjGQ6pzc",
        "colab_type": "code",
        "outputId": "2c47c0c4-ddc3-4e2d-9139-18862629a2e4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A-eokqAt6oKv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!unzip -q /content/drive/My\\ Drive/upper_lower_zip.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Ap4-AhmQc1y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!unzip -q /content/testing_data_zip_2.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FJ1CEo84KbF6",
        "colab_type": "code",
        "outputId": "cee7c952-fa31-4001-d97e-ba231923025f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import torch\n",
        "torch.cuda.current_device()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iS3cCEX5KhhS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.nn as nn\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import transforms\n",
        "import torchvision.models as models\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "from PIL import Image\n",
        "from PIL import ImageFile\n",
        "use_cuda = torch.cuda.is_available()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KnpsfWrvKu4n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "img_std = [0.229,0.224,0.225]\n",
        "img_mean = [0.485,0.456,0.406]\n",
        "batch_size = 32\n",
        "\n",
        "train_transforms = transforms.Compose([\n",
        "                                transforms.ToTensor(),\n",
        "                                transforms.Normalize(img_mean,img_std)\n",
        "                                     ])\n",
        "train_dir = \"/content/upper_lower/valid/train\"\n",
        "valid_dir = \"/content/upper_lower/valid/val\"\n",
        "test_dir = \"/content/upper_lower/test\"\n",
        "\n",
        "#train_dataset = datasets.ImageFolder(train_dir,transform=train_transforms)\n",
        "#valid_dataset = datasets.ImageFolder(valid_dir,transform=train_transforms)\n",
        "test_dataset = datasets.ImageFolder(test_dir,transform=train_transforms)\n",
        "\n",
        "#trainloader = torch.utils.data.DataLoader(train_dataset,batch_size=batch_size,shuffle=True)\n",
        "#validloader = torch.utils.data.DataLoader(valid_dataset,batch_size=batch_size,shuffle=True)\n",
        "testloader = torch.utils.data.DataLoader(test_dataset,batch_size=batch_size,shuffle=True)\n",
        "\n",
        "loaders = {\n",
        "    #'train':trainloader,\n",
        "    #'valid':validloader,\n",
        "    'test':testloader\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xGsjSlGCNk5J",
        "colab_type": "code",
        "outputId": "0827122f-6541-406e-d5ed-477a3d90eb17",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "class FashionNet(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.encoder_net = models.resnet50(pretrained=True)\n",
        "    self.encoder_net = nn.Sequential(*list(self.encoder_net.children())[:-1])\n",
        "    \n",
        "    \n",
        "    \n",
        "    self.fc1 = nn.Sequential(nn.Dropout(0.4),\n",
        "                            nn.Linear(4096,512),\n",
        "                            nn.BatchNorm1d(num_features=512),\n",
        "                            nn.ReLU(True),\n",
        "                            nn.Dropout(0.2),\n",
        "                            nn.Linear(512,2),\n",
        "                            nn.LogSoftmax(dim=1))\n",
        "    \n",
        "  def forward(self,x):\n",
        "    upper_im = x[:,:,:,:224]\n",
        "    lower_im = x[:,:,:,224:]\n",
        "    upper_enc = self.encoder_net(upper_im).view((-1,2048))\n",
        "    lower_enc = self.encoder_net(lower_im).view((-1,2048))\n",
        "\n",
        "    score = self.fc1(torch.cat((upper_enc,lower_enc),dim=1))\n",
        "\n",
        "    return score\n",
        "    \n",
        "model = FashionNet()\n",
        "if use_cuda:\n",
        "  model.cuda()\n",
        "model.load_state_dict(torch.load(\"/content/drive/My Drive/upper_lower_4.pt\"))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "IncompatibleKeys(missing_keys=[], unexpected_keys=[])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pCTgzz7QOzds",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "criterion = nn.NLLLoss()\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(),lr=0.0001)\n",
        "scheduler = optim.lr_scheduler.StepLR(optimizer,step_size=3,gamma=0.2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z6lsFS74O7wW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(n_epochs,model,criterion,optimizer,scheduler,loaders,use_cuda,save_path):\n",
        "  valid_loss_min = np.Inf\n",
        "  valid_acc_min = 0\n",
        "  \n",
        "  for epoch in range(1,n_epochs+1):\n",
        "    valid_loss = 0\n",
        "    train_loss = 0\n",
        "    valid_corrects = 0\n",
        "    train_corrects = 0\n",
        "    \n",
        "    scheduler.step()\n",
        "    \n",
        "    # Training loop\n",
        "    model.train()\n",
        "    for data,target in tqdm(loaders['train']):\n",
        "      if use_cuda:\n",
        "        data,target = data.cuda(),target.cuda()\n",
        "        \n",
        "      optimizer.zero_grad()\n",
        "      \n",
        "      output = model(data)\n",
        "      \n",
        "      loss = criterion(output,target)\n",
        "      \n",
        "      loss.backward()\n",
        "      \n",
        "      optimizer.step()\n",
        "      \n",
        "      train_loss += loss.item()\n",
        "      \n",
        "      pred = output.data.max(1,keepdim=True)[1]\n",
        "      train_corrects += np.sum(np.squeeze(pred.eq(target.data.view_as(pred))).cpu().numpy())\n",
        "      \n",
        "    \n",
        "    #Validation loop\n",
        "    model.eval()\n",
        "    for data,target in tqdm(loaders['valid']):\n",
        "      if use_cuda:\n",
        "        data,target = data.cuda(),target.cuda()\n",
        "       \n",
        "      with torch.no_grad():\n",
        "        output = model(data)\n",
        "      \n",
        "      loss = criterion(output,target)\n",
        "      \n",
        "      valid_loss += loss.item()\n",
        "      \n",
        "      pred = output.data.max(1,keepdim=True)[1]\n",
        "      valid_corrects += np.sum(np.squeeze(pred.eq(target.data.view_as(pred))).cpu().numpy())\n",
        "    \n",
        "    valid_loss = valid_loss / len(loaders['valid'])\n",
        "    train_loss = train_loss / len(loaders['train'])\n",
        "    valid_accuracy = valid_corrects / (len(loaders['valid'])*batch_size)\n",
        "    train_accuracy = train_corrects / (len(loaders['train'])*batch_size)\n",
        "      \n",
        "    #Print epoch details\n",
        "    print(\"Epoch: {}, Training loss: {}, Training accuracy: {}, Valid loss: {}, Valid accuracy; {}\".format(epoch,train_loss,train_accuracy,valid_loss,valid_accuracy))\n",
        "    \n",
        "    if valid_loss < valid_loss_min:\n",
        "      valid_loss_min = valid_loss\n",
        "      valid_acc_min = valid_accuracy\n",
        "      checkpoint = model.state_dict()\n",
        "      torch.save(checkpoint,save_path)\n",
        "      \n",
        "  print(\"The best model had a validation loss of {} and an accuracy of {}\".format(valid_loss_min,valid_acc_min))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wymqaqk-8L7j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = train(15,model,criterion,optimizer,scheduler,loaders,use_cuda,\"/content/drive/My Drive/upper_lower_4.pt\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rsh9_Dle8Vu-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def test(loaders, model, criterion, use_cuda):\n",
        "\n",
        "    # Monitor test loss and accuracy\n",
        "    test_loss = 0.\n",
        "    correct = 0.\n",
        "    total = 0.\n",
        "    \n",
        "    TP = 0\n",
        "    FP = 0\n",
        "    TN = 0\n",
        "    FN = 0\n",
        "\n",
        "    model.eval()\n",
        "    for batch_idx, (data, target) in tqdm(enumerate(loaders['test'])):\n",
        "        # Move to GPU\n",
        "        if use_cuda:\n",
        "            data, target = data.cuda(), target.cuda()\n",
        "        \n",
        "        # Find the model's prediction\n",
        "        output = model(data)\n",
        "        \n",
        "        # Calculate the loss\n",
        "        loss = criterion(output, target)\n",
        "        \n",
        "        # Update average test loss \n",
        "        test_loss = test_loss + ((1 / (batch_idx + 1)) * (loss.data - test_loss))\n",
        "        \n",
        "        # Update the test accuracy\n",
        "        pred = output.data.max(1, keepdim=True)[1]\n",
        "        \n",
        "        for idx in range(len(target)):\n",
        "          if target[idx] == 1:\n",
        "            if pred[idx] == 1:\n",
        "              TP += 1\n",
        "            else:\n",
        "              FN += 1\n",
        "          else:\n",
        "            if pred[idx] == 0:\n",
        "              TN += 1\n",
        "            else:\n",
        "              FP += 1\n",
        "    accuracy = (TP+TN)/(TP+FP+FN+TN)\n",
        "    precision = TP/(TP+FP)\n",
        "    recall = TP/(TP+FN)\n",
        "    f1 = 2*(recall * precision) / (recall + precision)\n",
        "     \n",
        "    # Print test loss and accuracy\n",
        "    print('accuracy: {}, precision: {}, recall: {}, f1: {}'.format(accuracy,precision,recall,f1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_bnnMPWRRQS6",
        "colab_type": "code",
        "outputId": "52a8e18b-8b54-4d88-ad52-b70e92711c94",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "test(loaders,model,criterion,use_cuda)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "666it [03:24,  3.22it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "accuracy: 0.6570476726726727, precision: 0.682796286182414, recall: 0.5866178678678678, f1: 0.6310635505527232\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lnyS5-F0RS92",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}