{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Lower_Model.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "NBDkYupskpgI",
        "colab_type": "code",
        "outputId": "aa695ef1-4d6b-4ef3-d546-e51386744edd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5BaJAA5nkk77",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!unzip -q /content/drive/My\\ Drive/lower_zip.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GR7YYds7lGIf",
        "colab_type": "code",
        "outputId": "ea15bd0b-4028-4ba3-bcf4-599d1d749217",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "source": [
        "!pip install split-folders"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting split-folders\n",
            "  Downloading https://files.pythonhosted.org/packages/20/67/29dda743e6d23ac1ea3d16704d8bbb48d65faf3f1b1eaf53153b3da56c56/split_folders-0.3.1-py3-none-any.whl\n",
            "Installing collected packages: split-folders\n",
            "Successfully installed split-folders-0.3.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GZ7Rg_z3krMs",
        "colab_type": "code",
        "outputId": "740e13ad-5a64-425c-e5cc-97d97d09c174",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import split_folders\n",
        "split_folders.ratio(\"/content/lower\",output=\"/content/lower_data\",ratio=(.7,.1,.2))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Copying files: 45190 files [00:06, 6690.85 files/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gnk-oyCtkrPk",
        "colab_type": "code",
        "outputId": "87732e09-398b-41cf-fe14-111a41865e80",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import torch\n",
        "torch.cuda.current_device()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dWN9HWrQkrQ-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.nn as nn\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import transforms\n",
        "import torchvision.models as models\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "from PIL import Image\n",
        "from PIL import ImageFile\n",
        "use_cuda = torch.cuda.is_available()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_14cjTLZkrTa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "img_std = [0.229,0.224,0.225]\n",
        "img_mean = [0.485,0.456,0.406]\n",
        "batch_size = 64\n",
        "\n",
        "train_transforms = transforms.Compose([\n",
        "                                transforms.ToTensor(),\n",
        "                                transforms.Normalize(img_mean,img_std)\n",
        "                                     ])\n",
        "train_dir = \"/content/lower_data/train\"\n",
        "valid_dir = \"/content/lower_data/val\"\n",
        "test_dir = \"/content/lower_data/test\"\n",
        "\n",
        "train_dataset = datasets.ImageFolder(train_dir,transform=train_transforms)\n",
        "valid_dataset = datasets.ImageFolder(valid_dir,transform=train_transforms)\n",
        "test_dataset = datasets.ImageFolder(test_dir,transform=train_transforms)\n",
        "\n",
        "trainloader = torch.utils.data.DataLoader(train_dataset,batch_size=batch_size,shuffle=True)\n",
        "validloader = torch.utils.data.DataLoader(valid_dataset,batch_size=batch_size,shuffle=True)\n",
        "testloader = torch.utils.data.DataLoader(test_dataset,batch_size=batch_size,shuffle=True)\n",
        "\n",
        "loaders = {\n",
        "    'train':trainloader,\n",
        "    'valid':validloader,\n",
        "    'test':testloader\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7wDKDgfEkrVJ",
        "colab_type": "code",
        "outputId": "93cb5ca2-67cb-41a2-8e59-2bed5d435afc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "class LowerModel(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.encoder_net = models.resnet101(pretrained=True)\n",
        "    self.encoder_net = nn.Sequential(*list(self.encoder_net.children())[:-1])\n",
        "    \n",
        "    self.fc1 = nn.Sequential(nn.Dropout(0.4),\n",
        "                            nn.Linear(2048,256),\n",
        "                            nn.BatchNorm1d(num_features=256),\n",
        "                            nn.ReLU(True),\n",
        "                            nn.Dropout(0.1),\n",
        "                            nn.Linear(256,8),\n",
        "                            nn.LogSoftmax(dim=1))\n",
        "    \n",
        "  def forward(self,x):\n",
        "    encoding = self.encoder_net(x).view((-1,2048))\n",
        "    preds = self.fc1(encoding)\n",
        "\n",
        "    return preds\n",
        "    \n",
        "model = LowerModel()\n",
        "if use_cuda:\n",
        "  model.cuda()\n",
        "model.load_state_dict(torch.load(\"/content/drive/My Drive/lower_3.pt\"))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet101-5d3b4d8f.pth\" to /root/.cache/torch/checkpoints/resnet101-5d3b4d8f.pth\n",
            "100%|██████████| 178728960/178728960 [00:06<00:00, 29079974.58it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kUPqpdhYkraj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "criterion = nn.NLLLoss()\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(),lr=0.001)\n",
        "scheduler = optim.lr_scheduler.StepLR(optimizer,step_size=3,gamma=0.2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pdQyVCpfkrcK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(n_epochs,model,criterion,optimizer,scheduler,loaders,use_cuda,save_path):\n",
        "  valid_loss_min = np.Inf\n",
        "  valid_acc_min = 0\n",
        "  \n",
        "  for epoch in range(1,n_epochs+1):\n",
        "    valid_loss = 0\n",
        "    train_loss = 0\n",
        "    valid_corrects = 0\n",
        "    train_corrects = 0\n",
        "    \n",
        "    scheduler.step()\n",
        "    \n",
        "    # Training loop\n",
        "    model.train()\n",
        "    for data,target in tqdm(loaders['train']):\n",
        "      if use_cuda:\n",
        "        data,target = data.cuda(),target.cuda()\n",
        "        \n",
        "      optimizer.zero_grad()\n",
        "      \n",
        "      output = model(data)\n",
        "      \n",
        "      loss = criterion(output,target)\n",
        "      \n",
        "      loss.backward()\n",
        "      \n",
        "      optimizer.step()\n",
        "      \n",
        "      train_loss += loss.item()\n",
        "      \n",
        "      pred = output.data.max(1,keepdim=True)[1]\n",
        "      train_corrects += np.sum(np.squeeze(pred.eq(target.data.view_as(pred))).cpu().numpy())\n",
        "      \n",
        "    \n",
        "    #Validation loop\n",
        "    model.eval()\n",
        "    for data,target in tqdm(loaders['valid']):\n",
        "      if use_cuda:\n",
        "        data,target = data.cuda(),target.cuda()\n",
        "       \n",
        "      with torch.no_grad():\n",
        "        output = model(data)\n",
        "      \n",
        "      loss = criterion(output,target)\n",
        "      \n",
        "      valid_loss += loss.item()\n",
        "      \n",
        "      pred = output.data.max(1,keepdim=True)[1]\n",
        "      valid_corrects += np.sum(np.squeeze(pred.eq(target.data.view_as(pred))).cpu().numpy())\n",
        "    \n",
        "    valid_loss = valid_loss / len(loaders['valid'])\n",
        "    train_loss = train_loss / len(loaders['train'])\n",
        "    valid_accuracy = valid_corrects / (len(loaders['valid'])*batch_size)\n",
        "    train_accuracy = train_corrects / (len(loaders['train'])*batch_size)\n",
        "      \n",
        "    #Print epoch details\n",
        "    print(\"Epoch: {}, Training loss: {}, Training accuracy: {}, Valid loss: {}, Valid accuracy; {}\".format(epoch,train_loss,train_accuracy,valid_loss,valid_accuracy))\n",
        "    \n",
        "    if valid_loss < valid_loss_min:\n",
        "      valid_loss_min = valid_loss\n",
        "      valid_acc_min = valid_accuracy\n",
        "      checkpoint = model.state_dict()\n",
        "      torch.save(checkpoint,save_path)\n",
        "      \n",
        "  print(\"The best model had a validation loss of {} and an accuracy of {}\".format(valid_loss_min,valid_acc_min))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TF8Y2HA9kreJ",
        "colab_type": "code",
        "outputId": "77d5da62-1948-4c41-d908-957b33ff7a60",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 810
        }
      },
      "source": [
        "model = train(15,model,criterion,optimizer,scheduler,loaders,use_cuda,\"/content/drive/My Drive/lower_3.pt\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 495/495 [06:23<00:00,  1.66it/s]\n",
            "100%|██████████| 71/71 [00:22<00:00,  3.68it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1, Training loss: 0.6312787810961406, Training accuracy: 0.803125, Valid loss: 0.5889344903784739, Valid accuracy; 0.8076584507042254\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 495/495 [06:26<00:00,  1.66it/s]\n",
            "100%|██████████| 71/71 [00:22<00:00,  3.66it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 2, Training loss: 0.4497705571278177, Training accuracy: 0.8613320707070707, Valid loss: 0.43182792567031486, Valid accuracy; 0.8657570422535211\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 495/495 [06:25<00:00,  1.67it/s]\n",
            "100%|██████████| 71/71 [00:21<00:00,  3.71it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 3, Training loss: 0.30655904287340663, Training accuracy: 0.9047348484848485, Valid loss: 0.30090825175735314, Valid accuracy; 0.9007482394366197\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 495/495 [06:25<00:00,  1.65it/s]\n",
            "100%|██████████| 71/71 [00:22<00:00,  3.63it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 4, Training loss: 0.25033620254258915, Training accuracy: 0.9225378787878787, Valid loss: 0.2808420305520716, Valid accuracy; 0.910431338028169\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 495/495 [06:27<00:00,  1.65it/s]\n",
            "100%|██████████| 71/71 [00:22<00:00,  3.65it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 5, Training loss: 0.2037824399543531, Training accuracy: 0.9362689393939394, Valid loss: 0.27349847943430217, Valid accuracy; 0.9117517605633803\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 495/495 [06:27<00:00,  1.65it/s]\n",
            "100%|██████████| 71/71 [00:22<00:00,  3.64it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 6, Training loss: 0.12757539257708223, Training accuracy: 0.961395202020202, Valid loss: 0.2517055987682141, Valid accuracy; 0.9209947183098591\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 495/495 [06:25<00:00,  1.66it/s]\n",
            "100%|██████████| 71/71 [00:22<00:00,  3.69it/s]\n",
            "  0%|          | 0/495 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 7, Training loss: 0.09732953343126509, Training accuracy: 0.9701388888888889, Valid loss: 0.25211938077085455, Valid accuracy; 0.9236355633802817\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 495/495 [06:26<00:00,  1.66it/s]\n",
            "100%|██████████| 71/71 [00:22<00:00,  3.66it/s]\n",
            "  0%|          | 0/495 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 8, Training loss: 0.07860141226814853, Training accuracy: 0.9766098484848484, Valid loss: 0.2549953475909334, Valid accuracy; 0.9264964788732394\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 495/495 [06:27<00:00,  1.65it/s]\n",
            "100%|██████████| 71/71 [00:22<00:00,  3.66it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 9, Training loss: 0.05837078846690029, Training accuracy: 0.983459595959596, Valid loss: 0.2499830701821287, Valid accuracy; 0.9271566901408451\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 495/495 [06:26<00:00,  1.65it/s]\n",
            "100%|██████████| 71/71 [00:22<00:00,  3.66it/s]\n",
            "  0%|          | 0/495 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 10, Training loss: 0.053873707892166244, Training accuracy: 0.9843434343434343, Valid loss: 0.2538936859600141, Valid accuracy; 0.9273767605633803\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 495/495 [06:27<00:00,  1.66it/s]\n",
            "100%|██████████| 71/71 [00:22<00:00,  3.68it/s]\n",
            "  0%|          | 0/495 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 11, Training loss: 0.048966784504326906, Training accuracy: 0.986395202020202, Valid loss: 0.2583309165661184, Valid accuracy; 0.9258362676056338\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 495/495 [06:25<00:00,  1.66it/s]\n",
            "100%|██████████| 71/71 [00:22<00:00,  3.69it/s]\n",
            "  0%|          | 0/495 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 12, Training loss: 0.04411957571753348, Training accuracy: 0.9878472222222222, Valid loss: 0.25629299018584506, Valid accuracy; 0.9262764084507042\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 495/495 [06:25<00:00,  1.66it/s]\n",
            "100%|██████████| 71/71 [00:21<00:00,  3.69it/s]\n",
            "  0%|          | 0/495 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 13, Training loss: 0.04349165569351177, Training accuracy: 0.9882575757575758, Valid loss: 0.26192085565605633, Valid accuracy; 0.9262764084507042\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 495/495 [06:25<00:00,  1.66it/s]\n",
            "100%|██████████| 71/71 [00:22<00:00,  3.66it/s]\n",
            "  0%|          | 0/495 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 14, Training loss: 0.041965647564843445, Training accuracy: 0.9880997474747475, Valid loss: 0.2647376997579991, Valid accuracy; 0.926056338028169\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 495/495 [06:26<00:00,  1.66it/s]\n",
            "100%|██████████| 71/71 [00:22<00:00,  3.68it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 15, Training loss: 0.04185700525689607, Training accuracy: 0.9888573232323232, Valid loss: 0.26480908392810487, Valid accuracy; 0.9258362676056338\n",
            "The best model had a validation loss of 0.2499830701821287 and an accuracy of 0.9271566901408451\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gqogFyTxkrYz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def test(loaders, model, criterion, use_cuda):\n",
        "\n",
        "    # Monitor test loss and accuracy\n",
        "    test_loss = 0.\n",
        "    correct = 0.\n",
        "    total = 0.\n",
        "    \n",
        "    TP = 0\n",
        "    FP = 0\n",
        "    TN = 0\n",
        "    FN = 0\n",
        "\n",
        "    model.eval()\n",
        "    for batch_idx, (data, target) in tqdm(enumerate(loaders['test'])):\n",
        "        # Move to GPU\n",
        "        if use_cuda:\n",
        "            data, target = data.cuda(), target.cuda()\n",
        "        \n",
        "        # Find the model's prediction\n",
        "        output = model(data)\n",
        "        \n",
        "        # Calculate the loss\n",
        "        loss = criterion(output, target)\n",
        "        \n",
        "        # Update average test loss \n",
        "        test_loss = test_loss + ((1 / (batch_idx + 1)) * (loss.data - test_loss))\n",
        "        \n",
        "        # Update the test accuracy\n",
        "        pred = output.data.max(1, keepdim=True)[1]\n",
        "        \n",
        "        for idx in range(len(target)):\n",
        "          if target[idx] == 1:\n",
        "            if pred[idx] == 1:\n",
        "              TP += 1\n",
        "            else:\n",
        "              FN += 1\n",
        "          else:\n",
        "            if pred[idx] == 0:\n",
        "              TN += 1\n",
        "            else:\n",
        "              FP += 1\n",
        "    accuracy = (TP+TN)/(TP+FP+FN+TN)\n",
        "    precision = TP/(TP+FP)\n",
        "    recall = TP/(TP+FN)\n",
        "    f1 = 2*(recall * precision) / (recall + precision)\n",
        "     \n",
        "    # Print test loss and accuracy\n",
        "    print('accuracy: {}, precision: {}, recall: {}, f1: {}'.format(accuracy,precision,recall,f1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "avi8Hz9RkrXq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}